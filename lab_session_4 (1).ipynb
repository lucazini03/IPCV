{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to PyTorch**\n",
        "## Image Processing and Computer Vision - Lab Session No. 4\n",
        "\n",
        "Contacts:\n",
        "\n",
        "- Prof. Giuseppe Lisanti -> giuseppe.lisanti@unibo.it\n",
        "- Prof. Samuele Salti -> samuele.salti@unibo.it\n",
        "- Alex Costanzino -> alex.costanzino@unibo.it\n",
        "- Francesco Ballerini -> francesco.ballerini4@unibo.it\n",
        "\n",
        "Based on the [UvA Deep Learning Course](https://uvadlc.github.io)."
      ],
      "metadata": {
        "id": "q-xdl8ay2YwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dependencies"
      ],
      "metadata": {
        "id": "XwNURhm8fhOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torchvision import transforms as T, datasets"
      ],
      "metadata": {
        "id": "BVQZKvyufiKb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Runtime settings\n",
        "\n",
        "For this hands-on session and the next one, we are going to train on GPUs. To request a GPU for you virtual machine in Colab, you should change your runtime type:\n",
        "\n",
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/uc14.png)"
      ],
      "metadata": {
        "id": "RLqo3_PHf0oE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch basics\n",
        "\n",
        "As a prerequisite, we recommend to be familiar with the `numpy` package as most machine learning frameworks are based on very similar concepts. If you are not familiar with NumPy yet, don't worry: here is a [tutorial](https://numpy.org/devdocs/user/quickstart.html) to go through.\n",
        "\n",
        "So, let's start with importing PyTorch and check its version:"
      ],
      "metadata": {
        "id": "H0-AgE93gCN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "id": "QC29pQZtfzoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee10ca1e-4fad-4429-ccac-b0d8c3bde7d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducibility\n",
        "When **developing and debugging** neural networks is desirable to have a deterministic behaviour (see *ablations*).\n",
        "\n",
        "For this reason, we are going to disable all the sources of randomness. Please note that completely reproducible results are not guaranteed (more detailed information at this [page](https://pytorch.org/docs/stable/notes/randomness.html)).\n",
        "\n",
        "Please note that the flag `cudnn.benchmark = False` disables the auto-tuner that selects the optimal set of algorithms for your hardware and usually leads to slower runtime."
      ],
      "metadata": {
        "id": "dgXBvsGKfuW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "    \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "    Args:\n",
        "        seed: the seed to use.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "fix_random(115)"
      ],
      "metadata": {
        "id": "aA2TAJhHfpff"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are the PyTorch equivalent to NumPy arrays, with the addition of also having support for GPU acceleration (more on that later).\n",
        "\n",
        "The name \"tensor\" is a generalization of concepts of arrays/matrices. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor.\n",
        "\n",
        "Most common functions you know from NumPy can be used on tensors as well. Actually, since NumPy arrays are so similar to tensors, we can convert most tensors to NumPy arrays (and back), although we don't need it too often."
      ],
      "metadata": {
        "id": "ngFCfpwCgREI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialization\n",
        "\n",
        "Let's first start by looking at different ways of creating a tensor. There are many possible options, the simplest one is to call `torch.Tensor` passing the desired shape as input argument:"
      ],
      "metadata": {
        "id": "Pu4jV7pX-Si5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "uDQiOHawgFPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a06b3bc-14e2-4a29-a23b-54fb9c553e74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.6468e+22,  4.3605e+27,  7.4334e+28,  1.7414e+25],\n",
            "         [ 2.2139e-10,  2.1596e+29,  6.8391e-40,  1.8206e-34],\n",
            "         [ 1.0097e-28,  1.0141e+31,  1.3593e-43,  0.0000e+00]],\n",
            "\n",
            "        [[-1.1061e-12,  4.5048e-41, -1.1061e-12,  4.5048e-41],\n",
            "         [ 1.5118e-38,  0.0000e+00,  1.5077e-38,  0.0000e+00],\n",
            "         [ 1.5118e-38,  0.0000e+00,  1.5077e-38,  0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been stored in the memory by default underlying processes (*uninitialized memory*).\n",
        "\n",
        "To directly assign values to the tensor during initialization, there are many alternatives including:\n",
        "\n",
        "* `torch.zeros`: creates a tensor filled with zeros\n",
        "* `torch.ones`: creates a tensor filled with ones\n",
        "* `torch.rand`: creates a tensor with random values uniformly sampled between 0 and 1\n",
        "* `torch.randn`: creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
        "* `torch.arange`: creates a tensor containing the values $N,N+1,N+2,...,M$\n",
        "* `torch.Tensor` (input list): creates a tensor from the list elements you provide"
      ],
      "metadata": {
        "id": "hLIXyENcgWh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor from a (nested) list\n",
        "x = torch.Tensor([[1, 2], [3, 4]])\n",
        "print(x)"
      ],
      "metadata": {
        "id": "UyBYyCOegTDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcbbc85-34f1-4d9e-ef8e-efff00f2eb19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "x = torch.rand(2, 3, 4)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "37LE_1X0gZB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354d76d1-5012-4382-84a7-cfd39a4a974e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1996, 0.6411, 0.9102, 0.0929],\n",
            "         [0.9051, 0.9735, 0.6610, 0.6851],\n",
            "         [0.3352, 0.6306, 0.7783, 0.1538]],\n",
            "\n",
            "        [[0.7183, 0.8051, 0.2333, 0.2414],\n",
            "         [0.2609, 0.6365, 0.9146, 0.4653],\n",
            "         [0.1533, 0.9062, 0.9542, 0.4817]]])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensor to NumPy, and NumPy to Tensor\n",
        "\n",
        "PyTorch tensors can be converted to NumPy arrays, and NumPy arrays back to tensors. To transform a NumPy array into a tensor, we can use the function `torch.from_numpy`:"
      ],
      "metadata": {
        "id": "Ew-ZZuvigdsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_arr = np.array([[1, 2], [3, 4]])\n",
        "tensor = torch.from_numpy(np_arr)\n",
        "\n",
        "print(f\"NumPy array:\\n{np_arr}\")\n",
        "print(f\"\\nPyTorch tensor:\\n{tensor}\")"
      ],
      "metadata": {
        "id": "xVwTEf8DgeDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337f6623-f9ba-4c5b-e580-1ef493478e85"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy array:\n",
            "[[1 2]\n",
            " [3 4]]\n",
            "\n",
            "PyTorch tensor:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform a PyTorch tensor back to a NumPy array, we can use the function `.numpy()` on tensors:"
      ],
      "metadata": {
        "id": "mWn5KkHXghtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(4)\n",
        "np_arr = tensor.numpy()\n",
        "\n",
        "print(f\"PyTorch tensor:\\n{tensor}\")\n",
        "print(f\"\\nNumpy array:\\n{np_arr}\")"
      ],
      "metadata": {
        "id": "zDu5t-bUgh79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75acb631-580f-47dc-ad11-137452129476"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch tensor:\n",
            "tensor([0, 1, 2, 3])\n",
            "\n",
            "Numpy array:\n",
            "[0 1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The conversion of tensors to NumPy requires the tensor to be on the CPU, and not the GPU (more on GPU support in a later section).\n",
        "\n",
        "In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like `np_arr = tensor.cpu().numpy()`."
      ],
      "metadata": {
        "id": "SRgeGtXmglxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basic operations\n"
      ],
      "metadata": {
        "id": "If8Fn80mguoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "y = x1 + x2\n",
        "\n",
        "print(f\"X1:\\n{x1}\")\n",
        "print(f\"X2:\\n{x2}\")\n",
        "print(f\"Y:\\n{y}\")"
      ],
      "metadata": {
        "id": "FTS9VAVWgmHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In-place operations are usually marked with a underscore postfix (e.g. `add_` instead of `add`):"
      ],
      "metadata": {
        "id": "uZusffRoELYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "print(f\"X1 (before):\\n{x1}\")\n",
        "print(f\"X2 (before):\\n{x2}\")\n",
        "\n",
        "x2.add_(x1)\n",
        "print(f\"X1 (after):\\n{x1}\")\n",
        "print(f\"X2 (after):\\n{x2}\")"
      ],
      "metadata": {
        "id": "TBHw7x7jgxpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another common operation aims at changing the shape of a tensor. A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6) or (3,2)). In PyTorch, this operation is called `view`:"
      ],
      "metadata": {
        "id": "Tsvfxz_7g0jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(6)\n",
        "print(f\"X:\\n{x}\")"
      ],
      "metadata": {
        "id": "FJ3akcLwg5QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.view(2, 3)\n",
        "print(f\"X:\\n{x}\")"
      ],
      "metadata": {
        "id": "mgPBjXQbg5Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.permute(1, 0)  # swap dimension 0 and 1\n",
        "print(f\"X:\\n{x}\")"
      ],
      "metadata": {
        "id": "EmgJr1nAg-dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU support"
      ],
      "metadata": {
        "id": "6EURHdNfiRQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "WOAcsnKoiTub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372d4498-9924-45bc-b44b-a7f4e736ed0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "id": "gO-TPsWwjN5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf4d4fd-2aa0-46dc-fcc1-992ed59d80db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(f\"X:\\n{x}\")"
      ],
      "metadata": {
        "id": "WIxwjjGGit23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c97e61-e3a0-4a47-d051-8711d4abd364"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you have a GPU, you should now see the attribute `device='cuda:0'` being printed next to your tensor. The `0` next to `cuda` indicates that this is the `0`-th GPU device on your computer. PyTorch also supports multi-GPU systems, but you will only need this feature once you have very big networks to train (if interested, see the [PyTorch documentation](https://pytorch.org/docs/stable/distributed.html#distributed-basics)).\n",
        "\n",
        "We can also compare the runtime of a large matrix multiplication on the CPU with the same operation on the GPU:"
      ],
      "metadata": {
        "id": "yfnrkVv1jQRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU version\n",
        "x = x.to(device)\n",
        "\n",
        "_ = torch.matmul(x, x)  # first operation to 'burn in' GPU\n",
        "\n",
        "# CUDA is asynchronous, so we need to use different timing functions\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "\n",
        "torch.cuda.synchronize()  # wait for everything to finish running on the GPU\n",
        "\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # milliseconds to seconds"
      ],
      "metadata": {
        "id": "CT8SX9k2jV-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd63dbcf-57a7-4045-bb1b-806b3e83c7a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 2.15208s\n",
            "GPU time: 0.08762s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dynamic Computation Graph and Backpropagation\n",
        "\n",
        "One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define. We will mainly use PyTorch for implementing neural networks, and they are just fancy functions. If we use weight matrices in our function that we want to learn, then those are called the **parameters** or simply the **weights**.\n",
        "\n",
        "Given an input $\\mathbf{x}$, we define our function by **manipulating** that input, usually by matrix-multiplications with weight matrices and additions with so-called bias vectors. As we manipulate our input, we are automatically creating a **computational graph**. This graph shows how to arrive at our output from our input.\n",
        "\n",
        "PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way.\n",
        "\n",
        "So, to recap: the only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**.\n",
        "\n",
        "> **Note:  Why do we want gradients?** Consider that we have defined a function, a neural net, that is supposed to compute a certain output $y$ for an input vector $\\mathbf{x}$. We then define an **error measure** that tells us how wrong our network is; how bad it is in predicting output $y$ from input $\\mathbf{x}$. Based on this error measure, we can use the gradients to **update** the weights $\\mathbf{W}$ that were responsible for the output, so that the next time we present input $\\mathbf{x}$ to our network, the output will be closer to what we want.\n",
        "\n",
        "The first thing we have to do is to specify which tensors require gradients. By default, when we create a tensor, it does not require gradients."
      ],
      "metadata": {
        "id": "tXFGealwhUTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((3,))\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "uxAXf-n4hUzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b240397d-4f32-489a-f5eb-84e3bf4a96d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation). Alternatively, when creating a tensor, you can pass the argument `requires_grad=True` to most initializers we have seen above."
      ],
      "metadata": {
        "id": "sX5lX1p-hYar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "f5-C-iAZhYyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4ff7ea-a2f6-4079-9b2f-129da032f384"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
        "\n",
        "$$y(x_i) = \\frac{1}{N}\\sum_{i=1}^N\\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "where $N$ denotes the number of elements in $\\mathbf{x}$. You could imagine that $\\mathbf{x}$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$. For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
      ],
      "metadata": {
        "id": "DRFyBLqxhaYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True)  # only float tensors can have gradients\n",
        "print(f\"X:\\n{x}\")"
      ],
      "metadata": {
        "id": "1yWKQVIBhcwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d1e24a-0483-4fe8-8486-af4e0c644a62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:\n",
            "tensor([0., 1., 2.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's build the computation graph step by step. You can combine multiple operations in a single line, but we will separate them here to get a better understanding of how each operation is added to the computation graph."
      ],
      "metadata": {
        "id": "mLQ-m-C4hhSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = x + 2\n",
        "print(\"a:\", a)\n",
        "b = a ** 2\n",
        "print(\"b:\", b)\n",
        "c = b + 3\n",
        "print(\"c:\", c)\n",
        "y = c.mean()\n",
        "print(\"Y:\", y)"
      ],
      "metadata": {
        "id": "49u8xvJ_hjqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df48e730-05ba-46bf-a1f5-54ba5591701a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([2., 3., 4.], grad_fn=<AddBackward0>)\n",
            "b: tensor([ 4.,  9., 16.], grad_fn=<PowBackward0>)\n",
            "c: tensor([ 7., 12., 19.], grad_fn=<AddBackward0>)\n",
            "Y: tensor(12.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the statements above, we have created a computation graph that looks similar to the figure below:\n",
        "\n",
        "![](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" width="171px" height="301px" viewBox="-0.5 -0.5 171 301"><defs/><g><ellipse cx="145" cy="15" rx="25" ry="15" fill="#cdeb8b" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 15px; margin-left: 121px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; ">x</div></div></div></foreignObject><text x="145" y="20" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">x</text></switch></g><ellipse cx="65" cy="15" rx="25" ry="15" fill="#eeeeee" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 15px; margin-left: 41px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span style="font-weight: normal">2</span></div></div></div></foreignObject><text x="65" y="20" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">2</text></switch></g><ellipse cx="105" cy="85" rx="25" ry="15" fill="#ffcc99" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 85px; margin-left: 81px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span>a</span></div></div></div></foreignObject><text x="105" y="90" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">a</text></switch></g><path d="M 112.58 70.71 L 132.15 34.12" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 134.62 29.49 L 134.41 37.31 L 132.15 34.12 L 128.24 34.01 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><path d="M 98.45 69.49 L 77.06 33.52" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 74.37 29.01 L 80.96 33.24 L 77.06 33.52 L 74.94 36.82 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><ellipse cx="105" cy="155" rx="25" ry="15" fill="#ffcc99" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 155px; margin-left: 81px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span>b</span></div></div></div></foreignObject><text x="105" y="160" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">b</text></switch></g><path d="M 105 140 L 105 106.37" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 105 101.12 L 108.5 108.12 L 105 106.37 L 101.5 108.12 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><ellipse cx="65" cy="225" rx="25" ry="15" fill="#ffcc99" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 225px; margin-left: 41px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span>c</span></div></div></div></foreignObject><text x="65" y="230" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">c</text></switch></g><ellipse cx="25" cy="155" rx="25" ry="15" fill="#eeeeee" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 155px; margin-left: 1px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span style="font-weight: normal">3</span></div></div></div></foreignObject><text x="25" y="160" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">3</text></switch></g><path d="M 71.78 210.56 L 88.84 174.35" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 91.07 169.6 L 91.26 177.43 L 88.84 174.35 L 84.92 174.44 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><path d="M 57 211.71 L 36.16 174.75" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 33.58 170.18 L 40.07 174.56 L 36.16 174.75 L 33.97 177.99 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><ellipse cx="65" cy="285" rx="25" ry="15" fill="#ffcc99" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 285px; margin-left: 41px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span style="font-weight: normal">y</span></div></div></div></foreignObject><text x="65" y="290" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">y</text></switch></g><path d="M 65 270 L 65 246.37" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 65 241.12 L 68.5 248.12 L 65 246.37 L 61.5 248.12 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/></g><switch><g requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"/><a transform="translate(0,-5)" xlink:href="https://desk.draw.io/support/solutions/articles/16000042487" target="_blank"><text text-anchor="middle" font-size="10px" x="50%" y="100%">Viewer does not support full SVG 1.1</text></a></switch></svg>)\n",
        "\n",
        "We can perform backpropagation on the computation graph by calling the function `backward()` on the last output, which effectively calculates the gradients for each tensor that has the property `requires_grad=True`:"
      ],
      "metadata": {
        "id": "IuPSEbQmhnUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "34H59ODhhnod"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathbf{x}$, and this gradient indicates how a change in $\\mathbf{x}$ will affect output $y$ given the current input $\\mathbf{x}=[0,1,2]$:"
      ],
      "metadata": {
        "id": "yj9ls_fSiFzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "metadata": {
        "id": "pUzoypZKiGNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16300ee2-9ae0-4baa-a504-78dcc0ab8a09"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3333, 2.0000, 2.6667])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also verify these gradients by hand. We will calculate the gradients using the chain rule, in the same way as PyTorch did it:\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$\n",
        "\n",
        "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor. Since\n",
        "\n",
        "$$\n",
        "a_i=x_i+2, \\quad\n",
        "b_i=a_i^2, \\quad\n",
        "c_i=b_i+3, \\quad\n",
        "y=\\frac{1}{N}\\sum_{i=1}^N c_i\n",
        "$$\n",
        "\n",
        "The partial derivatives are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1, \\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i, \\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1, \\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Hence $\\partial y/\\partial x_i=\\frac{2}{3}(x_i+2)$.\n",
        "\n",
        "Thus, being the input $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$. The previous code cell should have printed the same result."
      ],
      "metadata": {
        "id": "SAjQg5reiHwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's build our first Neural Network!\n",
        "\n",
        "We are now going to create a simple neural network that classifies images from the [Street View House Numbers (SVHN) dataset](http://ufldl.stanford.edu/housenumbers/):\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1200/1*X-VO9sZXIaHxh3aF-CRXZg.png)\n",
        "\n",
        "SVHN contains 600K 32x32 RGB images of printed digits (from 0 to 9) cropped from pictures of house number plates."
      ],
      "metadata": {
        "id": "rMpYB7E3jl65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data\n",
        "\n",
        "Download the dataset:"
      ],
      "metadata": {
        "id": "tl6T_miQjtDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsfms = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Lambda(lambda x: x.flatten())\n",
        "])\n",
        "\n",
        "train_dset = datasets.SVHN(\n",
        "    root=\"/data/\",\n",
        "    split=\"train\",\n",
        "    transform=tsfms,\n",
        "    download=True\n",
        ")\n",
        "test_dset = datasets.SVHN(\n",
        "    root=\"/data/\",\n",
        "    split=\"test\",\n",
        "    transform=tsfms,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "n_classes = 10\n",
        "\n",
        "input_dim = len(train_dset[0][0])"
      ],
      "metadata": {
        "id": "mheve-u1jpx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d03231-55e4-4923-d909-44ecdd00d0c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182M/182M [00:01<00:00, 106MB/s]\n",
            "100%|██████████| 64.3M/64.3M [00:01<00:00, 55.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, ax = plt.subplots(1, 4)\n",
        "\n",
        "for i, idx in enumerate([0, 10, 20, 30]):\n",
        "    img, label = test_dset[idx]\n",
        "    ax[i].imshow(img.reshape(3, 32, 32).permute(1, 2, 0))\n",
        "    ax[i].set_title(label)\n",
        "    ax[i].axis(\"off\")"
      ],
      "metadata": {
        "id": "PUlnsRp7MWuY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "1dd611ce-f8e9-410d-b034-1502bd0fb823"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a small validation set from the training set:"
      ],
      "metadata": {
        "id": "VmPTtqPhkYBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_subdset, val_subdset = random_split(\n",
        "    train_dset,\n",
        "    [len(train_dset) - 5000, 5000]\n",
        ")"
      ],
      "metadata": {
        "id": "MfooUAojkBIe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The data loader class\n",
        "\n",
        "The class `torch.utils.data.DataLoader` represents a Python iterable over a dataset with support for automatic batching, multi-process data loading and many more features. The data loader communicates with the dataset using the `__getitem__` function, and stacks its outputs as tensors over the first dimension to form a batch.\n",
        "In contrast to the dataset class, we usually don't have to define our own data loader class, but can just create an object of it with the dataset as input. Additionally, we can configure our data loader with the following input arguments (only a selection, see full list [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n",
        "\n",
        "* `batch_size`: number of samples to stack per batch.\n",
        "* `shuffle`: if True, the data is returned in a random order. This is important during training for introducing stochasticity.\n",
        "* `num_workers`: number of subprocesses to use for data loading. The default, 0, means that the data will be loaded in the main process which can slow down training for datasets where loading a data point takes a considerable amount of time (e.g. large images). More workers are recommended for those, but can cause issues on Windows computers. For tiny datasets as ours, 0 workers are usually faster.\n",
        "* `pin_memory`: if True, the data loader will copy tensors into CUDA pinned memory before returning them. This can save some time for large data points on GPUs. Usually a good practice to use for a training set, but not necessarily for validation and test to save memory on the GPU.\n",
        "* `drop_last`: If True, the last batch is dropped in case it is smaller than the specified batch size. This occurs when the dataset size is not a multiple of the batch size. Only potentially helpful during training to keep a consistent batch size.\n",
        "\n",
        "Let's create a simple data loader below:"
      ],
      "metadata": {
        "id": "ZR8Cj93vnSLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_subdset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "val_dl = DataLoader(\n",
        "    val_subdset,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "test_dl = DataLoader(\n",
        "    test_dset,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "J_7Pg2jAkH3H"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs, data_labels = next(iter(train_dl)) #256 input images of size 3072 (32*3*3 = 3072)\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the\n",
        "# dimensions of the data point returned from the dataset class\n",
        "print(f\"Data inputs: {data_inputs.shape}\\n{data_inputs}\")\n",
        "print(f\"\\nData labels: {data_labels.shape}\\n{data_labels}\")"
      ],
      "metadata": {
        "id": "1rR2Vw5mnZjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e532d99-64aa-4d93-c331-c446c18fccab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inputs: torch.Size([256, 3072])\n",
            "tensor([[0.4157, 0.3725, 0.3176,  ..., 0.2078, 0.1882, 0.2000],\n",
            "        [0.4314, 0.4275, 0.4157,  ..., 0.8353, 0.8588, 0.8745],\n",
            "        [0.4941, 0.4784, 0.4510,  ..., 0.4745, 0.4706, 0.4706],\n",
            "        ...,\n",
            "        [0.5176, 0.5137, 0.5098,  ..., 0.5725, 0.5804, 0.5725],\n",
            "        [0.1412, 0.1373, 0.1216,  ..., 0.5922, 0.6157, 0.6314],\n",
            "        [0.4235, 0.4235, 0.4314,  ..., 0.5608, 0.5412, 0.5294]])\n",
            "\n",
            "Data labels: torch.Size([256])\n",
            "tensor([6, 5, 4, 2, 5, 4, 1, 2, 3, 9, 1, 3, 3, 0, 5, 2, 3, 6, 8, 2, 3, 1, 2, 7,\n",
            "        1, 2, 7, 2, 2, 1, 0, 6, 9, 3, 3, 3, 1, 2, 6, 4, 8, 5, 5, 7, 5, 2, 6, 4,\n",
            "        1, 7, 8, 3, 1, 9, 3, 4, 2, 6, 5, 3, 7, 2, 8, 2, 7, 2, 3, 0, 1, 1, 9, 6,\n",
            "        2, 3, 0, 5, 2, 0, 1, 8, 1, 9, 2, 7, 3, 2, 7, 5, 2, 5, 4, 5, 1, 5, 4, 0,\n",
            "        1, 1, 5, 1, 4, 1, 5, 9, 0, 1, 0, 5, 4, 5, 4, 7, 3, 8, 2, 5, 2, 2, 3, 1,\n",
            "        4, 2, 1, 1, 6, 4, 3, 5, 0, 1, 1, 2, 3, 1, 1, 5, 3, 1, 3, 1, 1, 3, 4, 8,\n",
            "        0, 3, 9, 5, 5, 8, 9, 8, 2, 7, 2, 5, 9, 6, 4, 1, 1, 4, 4, 3, 1, 2, 0, 2,\n",
            "        5, 1, 6, 1, 2, 4, 5, 8, 6, 9, 4, 5, 5, 3, 9, 1, 4, 2, 2, 8, 0, 4, 8, 6,\n",
            "        8, 8, 5, 4, 5, 1, 7, 0, 1, 3, 2, 2, 2, 4, 0, 1, 6, 2, 9, 1, 8, 3, 3, 5,\n",
            "        3, 8, 2, 5, 1, 1, 7, 1, 1, 5, 7, 8, 6, 1, 3, 4, 5, 6, 5, 3, 5, 3, 7, 2,\n",
            "        2, 2, 3, 1, 2, 5, 3, 4, 2, 3, 8, 0, 5, 5, 5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the network\n",
        "\n",
        "We will then create our first neural network. One way to create neural networks in PyTorch is by subclassing `torch.nn.Module`. In this way, our model will inherit a lot of ready-to-use convinience functions (access to parameters for optimization, get/set parameters, etc.).\n",
        "\n",
        "We only need to create the layers we will use in the `__init__` function and define the `forward` function that specifies how to apply them.\n",
        "\n",
        "Layers are in turn subclasses of `torch.nn.Module`. In our example, we will use only linear layers, i.e. Fully Connected (FC) layers. Our network will have at least two FC layers: `self.first`, mapping the flattened input image into the (first) hidden representation, and `self.last`, mapping the (last) hidden representation into the scores for the classes. `n_hidden_layers` specifies how many hidden layers our network has (`self.first` and `self.last` not included).\n",
        "\n",
        "\n",
        "Note that to store a variable number of layers in our network we do not use plain Python lists, but `torch.nn.ModuleList`. This is important to make PyTorch aware of the layers in the list, e.g. to set/get their parameters when calling the methods of the base `Module` class."
      ],
      "metadata": {
        "id": "M7bO5sVVkLaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_classes, n_hidden_layers=0):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize the modules we need to build the network\n",
        "        self.first = nn.Linear(input_dim, hidden_dim) #linear fully connected layer that transforms the dimension from input dimension to hidden dimension\n",
        "        self.activation = nn.ReLU()\n",
        "        self.last = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim, hidden_dim) for i in range(n_hidden_layers)\n",
        "        ]) #the hidden layers consist of a list (ModuleList) of linear fully connected layers\n",
        "\n",
        "    #in the constructor we statically define all the components of the classifier, now in the forward method we define how the data flows through it: first layer, activation,\n",
        "    #hidden layers, and finally the last one, which outputs a logit for every possible class (10 digits -> 10 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.first(x)\n",
        "        x = self.activation(x)\n",
        "        for layer in self.hidden_layers: #For each hidden layer, apply the layer and then the activation function.\n",
        "            x = layer(x)\n",
        "            x = self.activation(x)\n",
        "        x = self.last(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ahhsPujbkL7I"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class implements a simple multilayer perceptron (MLP) for classification tasks. It allows:\n",
        "\n",
        "- An input layer\n",
        "- A configurable number of hidden layers (possibly zero)\n",
        "- An output layer that predicts the class scores (logits)\n",
        "\n"
      ],
      "metadata": {
        "id": "2JLAA1-4g-Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim = 128\n",
        "\n",
        "model = SimpleClassifier(\n",
        "    input_dim,\n",
        "    hidden_dim,\n",
        "    n_classes,\n",
        "    n_hidden_layers=1\n",
        ")\n",
        "for name, params in model.named_parameters():\n",
        "    print(f\"{name}: {params.shape}\")"
      ],
      "metadata": {
        "id": "2Z-UyxAAn_fX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879e894c-db18-4bd4-a3d4-3e7b3b77cf29"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first.weight: torch.Size([128, 3072])\n",
            "first.bias: torch.Size([128])\n",
            "last.weight: torch.Size([10, 128])\n",
            "last.bias: torch.Size([10])\n",
            "hidden_layers.0.weight: torch.Size([128, 128])\n",
            "hidden_layers.0.bias: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each linear layer has a weight matrix of shape `[output, input]`, and a bias of the shape `[output]`. The activation function does not have any parameters. Note that parameters are only registered for `nn.Module` objects that are direct object attributes, i.e. `self.a = ...`.\n",
        "\n",
        "`state_dict()` instead is an (ordered) dictionary, which associates each variable storing a layer with its parameters. It is therefore useful to obtain a snapshot of the parameters of our model that can later be restored by calling `load_state_dict()`."
      ],
      "metadata": {
        "id": "MqCpCn4vmt1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(model.state_dict())"
      ],
      "metadata": {
        "id": "Viqn0fgyqn0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09955945-405e-4f12-ec8d-6e980b8ac3dd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.OrderedDict"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict().keys()"
      ],
      "metadata": {
        "id": "TwTXNE8DqpLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bc6b1a-8d07-4205-b324-b892fadf4c18"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['first.weight', 'first.bias', 'last.weight', 'last.bias', 'hidden_layers.0.weight', 'hidden_layers.0.bias'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()[\"first.bias\"]"
      ],
      "metadata": {
        "id": "dBoWl-lpqqZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3876087f-e0d3-4f2e-a8bc-151f36699ba9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.3416e-02, -8.3404e-03, -6.5839e-03,  3.4606e-03, -5.3127e-04,\n",
              "        -5.8034e-03,  1.6759e-03,  4.2082e-03,  1.4430e-02, -1.3750e-02,\n",
              "        -1.2657e-02,  9.9703e-03,  1.2804e-03,  6.8770e-03,  7.0241e-03,\n",
              "         4.2756e-03,  1.2559e-02, -5.7716e-03, -1.2228e-02, -1.4300e-02,\n",
              "        -1.0254e-02, -9.5899e-03,  1.2115e-02, -1.5087e-02,  1.1634e-02,\n",
              "        -1.5434e-02, -1.7780e-02, -6.9847e-03, -1.5097e-02, -4.6314e-04,\n",
              "         3.7525e-03, -8.9080e-03, -5.9367e-03, -1.7170e-02, -3.9470e-03,\n",
              "         3.8286e-03, -2.1951e-03, -8.7630e-03, -5.2984e-03,  6.8927e-03,\n",
              "         1.0830e-02, -3.7191e-03, -6.1949e-05, -1.7439e-02, -1.0486e-02,\n",
              "         1.4927e-03, -4.9914e-03,  1.6269e-03, -1.1203e-02, -9.3735e-03,\n",
              "        -9.9247e-03,  1.6146e-03, -1.1583e-02,  1.0387e-03, -1.1283e-04,\n",
              "         1.0372e-02,  9.6582e-03,  4.6642e-03, -4.2489e-03, -1.7852e-02,\n",
              "        -1.6529e-02, -5.5827e-04, -1.3846e-03, -5.7895e-03,  1.2997e-02,\n",
              "        -3.2411e-03, -1.0085e-02,  1.5738e-02, -1.2867e-02, -1.3861e-02,\n",
              "        -1.0702e-02,  8.9311e-03,  6.7795e-03,  5.8779e-04,  1.4611e-02,\n",
              "        -7.1447e-05,  1.3442e-02, -1.6375e-02,  1.7347e-02,  2.5049e-03,\n",
              "         9.9429e-03,  1.7924e-02,  1.3363e-02, -5.5512e-03, -4.6667e-03,\n",
              "         1.0507e-02,  1.4543e-02, -8.9052e-03, -6.2054e-03, -6.7183e-03,\n",
              "         1.0186e-02, -7.4727e-03,  1.3603e-02, -7.2024e-03,  1.2012e-02,\n",
              "         4.7808e-03, -9.6339e-03,  1.4212e-02, -1.5484e-02,  5.1292e-03,\n",
              "         7.1864e-03,  1.5434e-02,  5.0233e-03,  1.4854e-02, -1.3634e-02,\n",
              "         1.2096e-02,  8.8845e-03,  5.2272e-03,  1.3591e-02, -1.5773e-03,\n",
              "         1.1289e-02,  1.3207e-02, -3.7387e-03,  4.0155e-03,  8.0196e-03,\n",
              "        -4.2790e-03,  1.0587e-02,  1.1780e-03,  4.3003e-03,  1.0411e-02,\n",
              "         1.3880e-02, -9.9481e-03, -2.9838e-04, -1.6559e-02,  5.2826e-03,\n",
              "        -6.5319e-03, -9.8811e-03, -1.2840e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push model to device. Has to be done only once.\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "hHdm_zLjpwCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef09c850-6134-40b4-acec-92cd19949ff1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleClassifier(\n",
              "  (first): Linear(in_features=3072, out_features=128, bias=True)\n",
              "  (activation): ReLU()\n",
              "  (last): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (hidden_layers): ModuleList(\n",
              "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization\n",
        "\n",
        "After defining the model and the dataset, it is time to prepare the optimization of the model. During training, we will perform the following steps:\n",
        "\n",
        "1. Get a batch from the data loader\n",
        "```\n",
        "for (x,y) in dataset:\n",
        "```\n",
        "2. Obtain the predictions from the model for the batch\n",
        "```\n",
        "y_pred = model(x)\n",
        "```\n",
        "3. Calculate the loss based on the difference between predictions and labels\n",
        "```\n",
        "loss = fcn(y_pred, y)\n",
        "```\n",
        "4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n",
        "```\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "```\n",
        "5. Update the parameters of the model in the direction of the gradients\n",
        "```\n",
        "optimizer.step()\n",
        "```\n",
        "To update the parameters, PyTorch provides the package `torch.optim` that has most popular optimizers implemented. We will for now use `torch.optim.Adam`."
      ],
      "metadata": {
        "id": "pMJ3jFu-nujg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "JAK9JOl3o-mE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimizer provides two useful functions: `optimizer.step()` and `optimizer.zero_grad()`. The step function updates the parameters based on the gradients as explained above.\n",
        "\n",
        "The function `optimizer.zero_grad()` sets the gradients of all parameters to zero. While this function seems less relevant at first, it is a crucial pre-step before performing backpropagation. If we call the `backward` function on the loss while the parameter gradients are non-zero from the previous batch, the new gradients will actually be added to the previous ones instead of overwriting them. This is done because a parameter might occur multiple times in a computation graph, and we need to sum the gradients in this case instead of replacing them. Hence, remember to call `optimizer.zero_grad()` before calculating the gradients of a batch."
      ],
      "metadata": {
        "id": "RrM17i7spNNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ncorrect(scores, y):\n",
        "    y_hat = torch.argmax(scores, -1)\n",
        "    return (y_hat == y).sum()\n",
        "\n",
        "def accuracy(scores, y):\n",
        "    correct = ncorrect(scores, y)\n",
        "    return correct.true_divide(y.shape[0])\n",
        "\n",
        "def train_loop(model, train_dl, epochs, opt, val_dl=None, verbose=False):\n",
        "    best_val_acc = 0\n",
        "    best_params = []\n",
        "    best_epoch = -1\n",
        "\n",
        "    for e in tqdm(range(epochs)):\n",
        "        # ----------[ Training loop ]---------- #\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_samples = 0\n",
        "        train_acc = 0\n",
        "\n",
        "        for train_data in train_dl:\n",
        "            imgs = train_data[0].to(device)\n",
        "            labels = train_data[1].to(device)\n",
        "\n",
        "            scores = model(imgs)\n",
        "\n",
        "            loss = F.cross_entropy(scores, labels)\n",
        "            train_loss += loss.item() * imgs.shape[0]\n",
        "            train_samples += imgs.shape[0]\n",
        "            train_acc += ncorrect(scores, labels).item()\n",
        "\n",
        "            opt.zero_grad()  # clear\n",
        "            loss.backward()  # fill\n",
        "            opt.step()       # use\n",
        "\n",
        "        train_acc /= train_samples\n",
        "        train_loss /= train_samples\n",
        "\n",
        "        # ----------[ Validation loop ]---------- #\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0\n",
        "            val_samples = 0\n",
        "            val_acc = 0\n",
        "\n",
        "            if val_dl is not None:\n",
        "                for val_data in val_dl:\n",
        "                    imgs = val_data[0].to(device)\n",
        "                    labels = val_data[1].to(device)\n",
        "\n",
        "                    val_scores = model(imgs)\n",
        "\n",
        "                    val_loss += F.cross_entropy(val_scores, labels).item() * imgs.shape[0]\n",
        "                    val_samples += imgs.shape[0]\n",
        "                    val_acc += ncorrect(val_scores, labels).item()\n",
        "                val_acc /= val_samples\n",
        "                val_loss /= val_samples\n",
        "\n",
        "            if val_dl is None or val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc if val_dl is not None else 0\n",
        "                best_params = model.state_dict()\n",
        "                torch.save(best_params, \"best_model.pth\")\n",
        "                best_epoch = e\n",
        "\n",
        "        if verbose and e % 5 == 0:\n",
        "            print(f\"Epoch {e}: train loss {train_loss:.3f} - train acc {train_acc:.3f}\" + (\"\" if val_dl is None else f\" - valid loss {val_loss:.3f} - valid acc {val_acc:.3f}\"))\n",
        "\n",
        "    if verbose and val_dl is not None:\n",
        "        print(f\"Best epoch {best_epoch}, best acc {best_val_acc}\")\n",
        "\n",
        "    return best_val_acc, best_params, best_epoch"
      ],
      "metadata": {
        "id": "RMHsGa-kktk6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the network"
      ],
      "metadata": {
        "id": "5C_cx4r3l3X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "best_val_acc, best_params, best_epoch = train_loop(\n",
        "    model,\n",
        "    train_dl,\n",
        "    epochs,\n",
        "    optimizer,\n",
        "    val_dl,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "JNNJCH0GVQ1r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "21729c8fb22c42f39fad31b7d34c2d45",
            "3e7ca7b8e7474c96b4cc19fefd29fd3d",
            "1c274ca1ebd54f07b81464827e6da98f",
            "2d73648174cc4cefb2c626f48d591b67",
            "c1eeba8d34794c7f873f500486f15959",
            "50bd46e2b1c548918131dadd7fe81fb4",
            "38075791d3fb4bd681b8833c99f6f537",
            "c0487e42459947a8b0e1b95f07b41bae",
            "43db435589be4d55aa201574c5e48d1d",
            "79b2569b644a4267b69aa981f7db8a05",
            "e54db0c4d3764ef897098f2c04d2fd9f"
          ]
        },
        "outputId": "f3fc5a6e-ddfb-4fbe-9c9d-c0d236635237"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21729c8fb22c42f39fad31b7d34c2d45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss 2.225 - train acc 0.188 - valid loss 2.151 - valid acc 0.215\n",
            "Epoch 5: train loss 1.303 - train acc 0.572 - valid loss 1.262 - valid acc 0.597\n",
            "Epoch 10: train loss 1.182 - train acc 0.620 - valid loss 1.186 - valid acc 0.623\n",
            "Epoch 15: train loss 1.112 - train acc 0.644 - valid loss 1.102 - valid acc 0.654\n",
            "Best epoch 19, best acc 0.6694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model"
      ],
      "metadata": {
        "id": "3DnMx-N8q6Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load state dict from the disk (make sure it is the same name as above)\n",
        "state_dict = torch.load(\"best_model.pth\")\n",
        "\n",
        "# Create a new model and load the state dict\n",
        "new_model = model = SimpleClassifier(\n",
        "    input_dim,\n",
        "    hidden_dim,\n",
        "    n_classes,\n",
        "    n_hidden_layers=1\n",
        ")\n",
        "new_model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "pfWY1VuWq7Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now it's your turn!"
      ],
      "metadata": {
        "id": "YX5S0oEt1pJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: improve the accuracy\n",
        "\n",
        "Try to achieve a better accuracy on the validation set by modifying the previous model and manually tuning the hyper-parameters such as the number of epochs, the learning rate, and the number of hidden layers.\n",
        "\n",
        "\n",
        "Also, add [Batch Normalization](https://arxiv.org/abs/1502.03167). You can find the normalization layers already implemented in PyTorch [here](https://pytorch.org/docs/stable/nn.html#normalization-layers). Use `torch.nn.Sequential` to stack together a block with the following\n",
        "structure: FC $\\rightarrow$ BatchNorm $\\rightarrow$ Activation.\n",
        "\n",
        "You should easily get 80% accuracy on the validation set.\n"
      ],
      "metadata": {
        "id": "FXoBf9ZF4o4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_linear_bn_relu(input_dim, out_dim):\n",
        "    \"\"\"Return a Sequential module with a sandwich of Linear, Batch Norm, and ReLU.\n",
        "\n",
        "    Args:\n",
        "        input_dim: the number of input features.\n",
        "        out_dim: the number of the output features.\n",
        "\n",
        "    Returns: the created Sequential block.\n",
        "    \"\"\"\n",
        "    modules = []\n",
        "    # ==================================================================== #\n",
        "    #                         YOUR CODE STARTS HERE                        #\n",
        "    # ==================================================================== #\n",
        "\n",
        "    # ==================================================================== #\n",
        "    #                         YOUR CODE ENDS HERE                          #\n",
        "    # ==================================================================== #\n",
        "\n",
        "    return nn.Sequential(*modules)"
      ],
      "metadata": {
        "id": "J5wwRfF41r6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifierBN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_classes, n_hidden_layers=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.first = get_linear_bn_relu(input_dim, hidden_dim)\n",
        "        self.last = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList([\n",
        "            get_linear_bn_relu(hidden_dim, hidden_dim) for i in range(n_hidden_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first(x)\n",
        "        for layer in self.hidden_layers:\n",
        "            x = layer(x)\n",
        "        x = self.last(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "tH_HHQX041fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================== #\n",
        "#                         YOUR CODE STARTS HERE                        #\n",
        "# ==================================================================== #\n",
        "\n",
        "# ==================================================================== #\n",
        "#                         YOUR CODE ENDS HERE                          #\n",
        "# ==================================================================== #\n",
        "\n",
        "best_val_acc, best_params, best_epoch = train_loop(\n",
        "    new_model,\n",
        "    train_dl,\n",
        "    epochs,\n",
        "    optimizer,\n",
        "    val_dl,\n",
        "    verbose=True)"
      ],
      "metadata": {
        "id": "s03EO1ev5JjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "id": "IqtXRfKEg74z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: confusion matrix\n",
        "Compute the confusion matrix for the test set. Then, from the confusion matrix, compute the accuracy score.\n",
        "\n",
        "> **Note:** a confusion matrix $\\mathbf{C}$ is such that $\\mathbf{C}_{ij}$ is equal to the number of samples known to belong to class $i$ and predicted to belong to class $j$."
      ],
      "metadata": {
        "id": "LAwjHfGV5Zyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5ywZvJlmK6ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.eval()\n",
        "confusion_matrix = torch.zeros(n_classes, n_classes, dtype=torch.int)\n",
        "# ==================================================================== #\n",
        "#                         YOUR CODE STARTS HERE                        #\n",
        "# ==================================================================== #\n",
        "\n",
        "# ==================================================================== #\n",
        "#                         YOUR CODE ENDS HERE                          #\n",
        "# ==================================================================== #\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "vuGfiC3vZMzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mtrx_df = pd.DataFrame(confusion_matrix)\n",
        "sn.heatmap(conf_mtrx_df, annot=True, fmt=\"d\");"
      ],
      "metadata": {
        "id": "TtbAcZVkbhZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: nearest neighbor search\n",
        "\n",
        "Rewrite the `forward` method of the classifier class to return the feature vector produced by the network right before the classification scores.\n",
        "\n",
        "> **Note:** you don't have to retrain the model again!\n",
        "\n",
        "Then, show the three nearest neighbors in the training set for element with index 0 in the test set."
      ],
      "metadata": {
        "id": "xjVl1dHK5Z3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifierBNv2(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_classes, n_hidden_layers=0):\n",
        "        super().__init__()\n",
        "\n",
        "        # ==================================================================== #\n",
        "        #                         YOUR CODE STARTS HERE                        #\n",
        "        # ==================================================================== #\n",
        "\n",
        "        # ==================================================================== #\n",
        "        #                         YOUR CODE ENDS HERE                          #\n",
        "        # ==================================================================== #\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ==================================================================== #\n",
        "        #                         YOUR CODE STARTS HERE                        #\n",
        "        # ==================================================================== #\n",
        "\n",
        "        # ==================================================================== #\n",
        "        #                         YOUR CODE ENDS HERE                          #\n",
        "        # ==================================================================== #"
      ],
      "metadata": {
        "id": "akoEz0AdveM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"best_model.pth\")\n",
        "\n",
        "new_model = SimpleClassifierBNv2(\n",
        "    input_dim,\n",
        "    hidden_dim,\n",
        "    n_classes,\n",
        "    n_hidden_layers=3\n",
        ")\n",
        "new_model.load_state_dict(state_dict)\n",
        "new_model.to(device)\n",
        "new_model.eval();"
      ],
      "metadata": {
        "id": "3teK1uxPvuoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feat_vecs(model, dl):\n",
        "    feat_vecs = []\n",
        "    labels = []\n",
        "    # ==================================================================== #\n",
        "    #                         YOUR CODE STARTS HERE                        #\n",
        "    # ==================================================================== #\n",
        "\n",
        "    # ==================================================================== #\n",
        "    #                         YOUR CODE ENDS HERE                          #\n",
        "    # ==================================================================== #\n",
        "\n",
        "    return feat_vecs, labels\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_subdset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False  # no shuffle here\n",
        ")\n",
        "feat_vecs_train, labels_train = get_feat_vecs(new_model, train_dl)\n",
        "feat_vecs_test, labels_test = get_feat_vecs(new_model, test_dl)"
      ],
      "metadata": {
        "id": "cgknZDtH4rpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_idx = 0\n",
        "\n",
        "# ==================================================================== #\n",
        "#                         YOUR CODE STARTS HERE                        #\n",
        "# ==================================================================== #\n",
        "\n",
        "# ==================================================================== #\n",
        "#                         YOUR CODE ENDS HERE                          #\n",
        "# ==================================================================== #"
      ],
      "metadata": {
        "id": "9oUEQ70OE5OT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21729c8fb22c42f39fad31b7d34c2d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7ca7b8e7474c96b4cc19fefd29fd3d",
              "IPY_MODEL_1c274ca1ebd54f07b81464827e6da98f",
              "IPY_MODEL_2d73648174cc4cefb2c626f48d591b67"
            ],
            "layout": "IPY_MODEL_c1eeba8d34794c7f873f500486f15959"
          }
        },
        "3e7ca7b8e7474c96b4cc19fefd29fd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50bd46e2b1c548918131dadd7fe81fb4",
            "placeholder": "​",
            "style": "IPY_MODEL_38075791d3fb4bd681b8833c99f6f537",
            "value": "100%"
          }
        },
        "1c274ca1ebd54f07b81464827e6da98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0487e42459947a8b0e1b95f07b41bae",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43db435589be4d55aa201574c5e48d1d",
            "value": 20
          }
        },
        "2d73648174cc4cefb2c626f48d591b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79b2569b644a4267b69aa981f7db8a05",
            "placeholder": "​",
            "style": "IPY_MODEL_e54db0c4d3764ef897098f2c04d2fd9f",
            "value": " 20/20 [03:28&lt;00:00, 10.50s/it]"
          }
        },
        "c1eeba8d34794c7f873f500486f15959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50bd46e2b1c548918131dadd7fe81fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38075791d3fb4bd681b8833c99f6f537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0487e42459947a8b0e1b95f07b41bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43db435589be4d55aa201574c5e48d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79b2569b644a4267b69aa981f7db8a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54db0c4d3764ef897098f2c04d2fd9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}